{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":26319,"databundleVersionId":2037275,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T06:26:44.642728Z","iopub.execute_input":"2025-07-19T06:26:44.643048Z","iopub.status.idle":"2025-07-19T06:26:46.663008Z","shell.execute_reply.started":"2025-07-19T06:26:44.643023Z","shell.execute_reply":"2025-07-19T06:26:46.662200Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ml2021spring-hw2/sampleSubmission.csv\n/kaggle/input/ml2021spring-hw2/timit_11/timit_11/train_11.npy\n/kaggle/input/ml2021spring-hw2/timit_11/timit_11/test_11.npy\n/kaggle/input/ml2021spring-hw2/timit_11/timit_11/train_label_11.npy\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\n\nprint('Loading data ...')\n\ndata_root='/kaggle/input/ml2021spring-hw2/timit_11/timit_11/'\ntrain = np.load(data_root + 'train_11.npy')\ntrain_label = np.load(data_root + 'train_label_11.npy')\ntest = np.load(data_root + 'test_11.npy')\n\nprint('Size of training data: {}'.format(train.shape))\nprint('Size of testing data: {}'.format(test.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:00:26.070466Z","iopub.execute_input":"2025-07-17T15:00:26.070881Z","iopub.status.idle":"2025-07-17T15:01:13.137888Z","shell.execute_reply.started":"2025-07-17T15:00:26.070856Z","shell.execute_reply":"2025-07-17T15:01:13.137041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass TIMITDataset(Dataset):\n    #初始化数据集对象\n    def __init__(self, X, y=None):\n        self.data = torch.from_numpy(X).float()\n        #若 y 存在，将其从 NumPy 数组转换为 LongTensor（要求标签为整数类型）。\n        #若 y 不存在（如测试阶段），self.label 设为 None。\n        if y is not None:\n            y = y.astype(np.int64) \n            self.label = torch.LongTensor(y)\n        else:\n            self.label = None\n\n    #通过索引 idx 获取单个样本（和标签）\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[idx], self.label[idx]\n        else:\n            return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:13.139663Z","iopub.execute_input":"2025-07-17T15:01:13.139943Z","iopub.status.idle":"2025-07-17T15:01:18.540890Z","shell.execute_reply.started":"2025-07-17T15:01:13.139921Z","shell.execute_reply":"2025-07-17T15:01:18.539445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#定义验证集的比例\nVAL_RATIO = 0.2\n#计算划分点\npercent = int(train.shape[0] * (1 - VAL_RATIO))\n#划分特征和标签\ntrain_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\nprint('Size of training set: {}'.format(train_x.shape))\nprint('Size of validation set: {}'.format(val_x.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:18.541924Z","iopub.execute_input":"2025-07-17T15:01:18.542314Z","iopub.status.idle":"2025-07-17T15:01:18.549625Z","shell.execute_reply.started":"2025-07-17T15:01:18.542288Z","shell.execute_reply":"2025-07-17T15:01:18.548545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#batch大小\nBATCH_SIZE = 512\n\nfrom torch.utils.data import DataLoader\n\n#创建数据集实例\ntrain_set = TIMITDataset(train_x, train_y)\nval_set = TIMITDataset(val_x, val_y)\n#创建数据加载器\n#DataLoader 参数解释：\n#dataset：传入的数据集（如 train_set）。\n#batch_size=BATCH_SIZE：每个批次加载的样本数（此处为 64）。\n#shuffle=True/False：\n#训练集（train_loader）：shuffle=True 表示每个 epoch 都会随机打乱数据顺序，防止模型学习到样本的特定顺序，提高泛化能力。\n#验证集（val_loader）：shuffle=False 表示按固定顺序加载数据，方便结果复现和评估模型性能。\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:18.550938Z","iopub.execute_input":"2025-07-17T15:01:18.551288Z","iopub.status.idle":"2025-07-17T15:01:22.631878Z","shell.execute_reply.started":"2025-07-17T15:01:18.551253Z","shell.execute_reply":"2025-07-17T15:01:22.630827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#释放不再使用的内存\nimport gc\n\ndel train, train_label, train_x, train_y, val_x, val_y\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:22.632989Z","iopub.execute_input":"2025-07-17T15:01:22.633322Z","iopub.status.idle":"2025-07-17T15:01:22.774144Z","shell.execute_reply.started":"2025-07-17T15:01:22.633290Z","shell.execute_reply":"2025-07-17T15:01:22.772886Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#用于语音识别的多层感知机（MLP）分类器\nimport torch\nimport torch.nn as nn\n\n# class Classifier(nn.Module):\n#     def __init__(self):\n#         super(Classifier, self).__init__()\n#         self.layer1 = nn.Linear(429, 1024)\n#         self.layer2 = nn.Linear(1024, 512)\n#         self.layer3 = nn.Linear(512, 128)\n#         self.out = nn.Linear(128, 39) \n\n#         self.act_fn = nn.ReLU()\n\n#     #向前传播函数\n#     def forward(self, x):\n#         x = self.layer1(x)#线性变换\n#         x = self.act_fn(x)#sigmoid激活\n\n#         x = self.layer2(x)\n#         x = self.act_fn(x)\n\n#         x = self.layer3(x)\n#         x = self.act_fn(x)\n\n#         x = self.out(x)\n        \n#         return x\n#将神经网络改为下面\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(429, 2048), # 1\n            nn.LeakyReLU(),\n            #nn.ReLU(),\n            nn.BatchNorm1d(2048),\n            nn.Dropout(0.5),\n            nn.Linear(2048, 2048), # 2\n            nn.LeakyReLU(),\n            #nn.ReLU(),\n            nn.BatchNorm1d(2048),\n            nn.Dropout(0.5),\n            nn.Linear(2048, 2048), # 2\n            nn.LeakyReLU(),\n            #nn.ReLU(),\n            nn.BatchNorm1d(2048),\n            nn.Dropout(0.5),\n            nn.Linear(2048,1024), # 3\n            nn.LeakyReLU(),\n            #nn.ReLU(),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 512), # 4\n            #nn.ReLU(),\n            nn.LeakyReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.5),\n            nn.Linear(512, 256), # 5\n            #nn.ReLU(),\n            nn.LeakyReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.5),\n            nn.Linear(256, 39)\n        )\n\n    def forward(self, x):\n        x = self.net(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:22.774864Z","iopub.execute_input":"2025-07-17T15:01:22.775227Z","iopub.status.idle":"2025-07-17T15:01:22.798760Z","shell.execute_reply.started":"2025-07-17T15:01:22.775194Z","shell.execute_reply":"2025-07-17T15:01:22.797746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check device\ndef get_device():\n  return 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:22.799670Z","iopub.execute_input":"2025-07-17T15:01:22.800075Z","iopub.status.idle":"2025-07-17T15:01:22.818487Z","shell.execute_reply.started":"2025-07-17T15:01:22.800041Z","shell.execute_reply":"2025-07-17T15:01:22.817610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 固定随机种子的函数\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)  \n    np.random.seed(seed)  \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:22.821524Z","iopub.execute_input":"2025-07-17T15:01:22.821846Z","iopub.status.idle":"2025-07-17T15:01:22.840349Z","shell.execute_reply.started":"2025-07-17T15:01:22.821820Z","shell.execute_reply":"2025-07-17T15:01:22.839290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fix random seed for reproducibility\n#随机种子设为0\nsame_seeds(0)\n\n# get device \ndevice = get_device()\nprint(f'DEVICE: {device}')\n\n# training parameters\nnum_epoch = 100              # 训练轮数\nlearning_rate = 0.0001       # learning rate\n\n# the path where checkpoint saved\nmodel_path = './model.ckpt'\n\n# create model, define a loss function, and optimizer\nmodel = Classifier().to(device)\ncriterion = nn.CrossEntropyLoss() #交叉熵\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#优化器Adam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:22.841387Z","iopub.execute_input":"2025-07-17T15:01:22.841716Z","iopub.status.idle":"2025-07-17T15:01:26.562454Z","shell.execute_reply.started":"2025-07-17T15:01:22.841682Z","shell.execute_reply":"2025-07-17T15:01:26.561475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# start training\n\nbest_acc = 0.0#记录最佳的准确率\nfor epoch in range(num_epoch):#训练循环\n    train_acc = 0.0  # 训练集总准确率\n    train_loss = 0.0  # 训练集总损失\n    val_acc = 0.0    # 验证集总准确率\n    val_loss = 0.0    # 验证集总损失\n\n    # training\n    model.train() # set the model to training mode\n    for i, data in enumerate(train_loader):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad() #清空梯度缓存\n        outputs = model(inputs) #向前传播，计算预测值\n        batch_loss = criterion(outputs, labels)#计算损失\n        _, train_pred = torch.max(outputs, 1) # # 获取预测类别（取概率最高的索引）\n        batch_loss.backward() #反向传播：计算梯度\n        optimizer.step() #更新模型参数\n\n        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()#统计正确预测数\n        train_loss += batch_loss.item()#累加批次损失\n\n    # validation\n    if len(val_set) > 0:\n        model.eval() # set the model to evaluation mode\n        with torch.no_grad():\n            for i, data in enumerate(val_loader):\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                batch_loss = criterion(outputs, labels) \n                _, val_pred = torch.max(outputs, 1) \n            \n                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n                val_loss += batch_loss.item()\n\n            #打印当前训练和验证指标\n            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n            ))\n\n            # if the model improves, save a checkpoint at this epoch\n            #保存最佳模型\n            if val_acc > best_acc:\n                best_acc = val_acc\n                torch.save(model.state_dict(), model_path)\n                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n    else:\n        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n        ))\n\n# if not validating, save the last epoch\nif len(val_set) == 0:\n    torch.save(model.state_dict(), model_path)\n    print('saving model at last epoch')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:01:26.563376Z","iopub.execute_input":"2025-07-17T15:01:26.563776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# create testing dataset\ntest_set = TIMITDataset(test, None)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n\n# create model and load weights from checkpoint\nmodel = Classifier().to(device)\nmodel.load_state_dict(torch.load(model_path))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict = []\nmodel.eval() # set the model to evaluation mode\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        inputs = data\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n\n        for y in test_pred.cpu().numpy():\n            predict.append(y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(predict):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}